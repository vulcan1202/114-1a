# ğŸ“‚ backend/whisper_app/tasks.py

import os
import gc
import re
import logging
import torch
import asyncio
from celery import shared_task
from django.apps import apps
from django.conf import settings
from django.db import transaction
from datetime import timedelta
from django.utils import timezone

# --- å¼•å…¥ WhisperX ç›¸é—œ ---
import whisperx
import whisperx.diarize

# --- å¼•å…¥ æ‘˜è¦ç›¸é—œ ---
from .summarization_utils import (
    qwen_load_model,
    generate_summary_with_qwen2_5,
    calculate_dynamic_lengths,
    _preprocess_text
)

# --- å¼•å…¥ ç¿»è­¯ç›¸é—œ ---
from googletrans import Translator
from langdetect import detect

logger = logging.getLogger(__name__)


# ==========================================
# 1. éŸ³è¨Šè½‰éŒ„ä»»å‹™ (æ ¸å¿ƒä¿®æ”¹)
# ==========================================

@shared_task(bind=True)
def transcribe_audio_task(self, audio_task_id, language=None, user_prompt="", enable_diarization=False):
    """
    Celery éåŒæ­¥è½‰éŒ„ä»»å‹™ï¼š
    1. å¾ DB è®€å– AudioTask
    2. åŸ·è¡Œ WhisperX è½‰éŒ„ + å°é½Š + (é¸ç”¨)èªªè©±è€…åˆ†é›¢
    3. å°‡çµæœå¯«å› DB (AudioTask & TranscriptSegment)
    """

    # åœ¨å‡½å¼å…§éƒ¨ import Models ä»¥é¿å…å¾ªç’°å¼•ç”¨
    from .models import AudioTask, TranscriptSegment, AudioTaskStatus

    logger.info(f"ğŸš€ [Task {audio_task_id}] é–‹å§‹åŸ·è¡Œè½‰éŒ„ä»»å‹™ã€‚")

    # 1. ç²å– App Config è¨­å®š
    try:
        whisper_app_config = apps.get_app_config('whisper_app')
        MODEL_SIZE = whisper_app_config.MODEL_SIZE
        COMPUTE_TYPE = whisper_app_config.COMPUTE_TYPE
        BATCH_SIZE = whisper_app_config.WHISPER_BATCH_SIZE
        DEVICE = whisper_app_config.DEVICE
        PYANN_DIARIZATION_MODEL = whisper_app_config.PYANN_DIARIZATION_MODEL
        HF_ACCESS_TOKEN = whisper_app_config.HF_ACCESS_TOKEN
    except Exception as e:
        logger.error(f"âŒ [Task {audio_task_id}] è®€å– Config å¤±æ•—: {e}")
        return {"status": "error", "error": str(e)}

    # åˆå§‹åŒ–è®Šæ•¸
    whisper_model = None
    align_model = None
    diarize_pipeline = None
    task_obj = None

    try:
        # --- 2. å¾è³‡æ–™åº«å–å¾—ä»»å‹™ç‰©ä»¶ & æ›´æ–°ç‹€æ…‹ ---
        try:
            task_obj = AudioTask.objects.get(id=audio_task_id)
            task_obj.status = AudioTaskStatus.PROCESSING
            task_obj.save()
            file_path = task_obj.audio_file.path  # å–å¾—å¯¦éš›æª”æ¡ˆè·¯å¾‘
        except AudioTask.DoesNotExist:
            logger.error(f"âŒ [Task {audio_task_id}] æ‰¾ä¸åˆ° DB ç´€éŒ„")
            return {"status": "error", "error": "AudioTask not found in DB"}

        if not os.path.exists(file_path):
            raise FileNotFoundError(f"å¯¦é«”æª”æ¡ˆä¸å­˜åœ¨: {file_path}")

        logger.info(f"[Task {audio_task_id}] è¼‰å…¥éŸ³è¨Šæª”æ¡ˆ: {file_path}")
        audio_waveform = whisperx.load_audio(file_path)

        # [æ›´æ–°] è¨ˆç®—ä¸¦å¯«å…¥éŸ³æª”é•·åº¦
        duration_sec = len(audio_waveform) / 16000  # WhisperX é è¨­æ¡æ¨£ç‡ 16k
        task_obj.duration = round(duration_sec, 2)
        task_obj.save(update_fields=['duration'])

        # --- 3. è¨­å®š Prompt ---
        base_initial_prompt = "æ‚¨å¥½ï¼Œè«‹å•ï¼Ÿè¬è¬ã€‚Hello, how are you? Thank you!"
        combined_initial_prompt = f"{base_initial_prompt} {user_prompt}" if user_prompt else base_initial_prompt
        asr_options = {"initial_prompt": combined_initial_prompt}

        # --- 4. Whisper è½‰éŒ„ (ASR) ---
        logger.info(f"[Task {audio_task_id}] è¼‰å…¥ Whisper æ¨¡å‹ ({MODEL_SIZE})...")
        whisper_model = whisperx.load_model(
            MODEL_SIZE,
            device=DEVICE,
            compute_type=COMPUTE_TYPE,
            asr_options=asr_options,
            vad_options={"no_speech_threshold": 0.45},
        )

        logger.info(f"[Task {audio_task_id}] åŸ·è¡Œ ASR è½‰éŒ„...")
        result = whisper_model.transcribe(
            audio_waveform,
            batch_size=BATCH_SIZE,
            language=language,
            chunk_size=30,
        )

        # é‡‹æ”¾ Whisper
        del whisper_model
        whisper_model = None
        gc.collect()
        if DEVICE == "cuda": torch.cuda.empty_cache()

        # --- 5. å°é½Š (Alignment) ---
        detected_language = result["language"]
        task_obj.language_code = detected_language  # æ›´æ–°åµæ¸¬åˆ°çš„èªè¨€

        logger.info(f"[Task {audio_task_id}] åµæ¸¬èªè¨€: {detected_language}ï¼Œé–‹å§‹å°é½Š...")
        align_model, align_metadata = whisperx.load_align_model(
            language_code=detected_language,
            device=DEVICE
        )

        result = whisperx.align(
            result["segments"],
            align_model,
            align_metadata,
            audio_waveform,
            DEVICE,
            return_char_alignments=False
        )

        # é‡‹æ”¾å°é½Šæ¨¡å‹
        del align_model
        del align_metadata
        align_model = None
        gc.collect()
        if DEVICE == "cuda": torch.cuda.empty_cache()

        # --- 6. èªªè©±è€…åˆ†é›¢ (Diarization) ---
        final_segments = result["segments"]

        if enable_diarization:
            if not HF_ACCESS_TOKEN:
                logger.warning(f"[Task {audio_task_id}] ç¼ºå°‘ HF Tokenï¼Œè·³é Diarization")
            else:
                logger.info(f"[Task {audio_task_id}] åŸ·è¡Œèªªè©±è€…åˆ†é›¢...")
                diarize_pipeline = whisperx.diarize.DiarizationPipeline(
                    model_name=PYANN_DIARIZATION_MODEL,
                    use_auth_token=HF_ACCESS_TOKEN,
                    device=DEVICE
                )
                diarize_segments = diarize_pipeline(audio_waveform)
                final_result = whisperx.assign_word_speakers(diarize_segments, result)
                final_segments = final_result["segments"]

                # é‡‹æ”¾åˆ†é›¢æ¨¡å‹
                del diarize_pipeline
                diarize_pipeline = None
                gc.collect()
                if DEVICE == "cuda": torch.cuda.empty_cache()

        # --- 7. è³‡æ–™å¯«å…¥è³‡æ–™åº« ---

        # A. çµ„åˆå…¨æ–‡
        full_text = " ".join([seg['text'].strip() for seg in final_segments])

        # B. å¯«å…¥ DB (ä½¿ç”¨ Transaction ç¢ºä¿åŸå­æ€§)
        with transaction.atomic():
            # æ›´æ–°ä¸»è¡¨
            task_obj.status = AudioTaskStatus.COMPLETED
            task_obj.full_transcript = full_text
            task_obj.enable_diarization = enable_diarization
            task_obj.save()

            # æ¸…é™¤èˆŠçš„ segments (å¦‚æœæ˜¯é‡è·‘ä»»å‹™çš„è©±)
            task_obj.segments.all().delete()

            # å»ºç«‹æ–°çš„ segments
            segments_to_create = []
            for seg in final_segments:
                segments_to_create.append(TranscriptSegment(
                    task=task_obj,
                    speaker_label=seg.get('speaker', None),
                    start_time=seg['start'],
                    end_time=seg['end'],
                    text=seg['text'].strip()
                ))

            # æ‰¹æ¬¡å¯«å…¥ï¼Œæ•ˆèƒ½è¼ƒå¥½
            TranscriptSegment.objects.bulk_create(segments_to_create)

        logger.info(f"âœ… [Task {audio_task_id}] è½‰éŒ„èˆ‡å­˜æª”å®Œæˆï¼")

        return {"status": "success", "task_id": str(audio_task_id)}

    except Exception as e:
        logger.error(f"âŒ [Task {audio_task_id}] ä»»å‹™å¤±æ•—: {str(e)}", exc_info=True)

        # éŒ¯èª¤æ™‚æ›´æ–° DB
        if task_obj:
            task_obj.status = AudioTaskStatus.FAILED
            task_obj.error_message = str(e)
            task_obj.save()

        return {"status": "error", "error": str(e)}

    finally:
        # --- 8. æœ€çµ‚æ¸…ç† ---
        if whisper_model is not None: del whisper_model
        if align_model is not None: del align_model
        if diarize_pipeline is not None: del diarize_pipeline
        gc.collect()
        if DEVICE == "cuda":
            torch.cuda.empty_cache()

        # æ³¨æ„ï¼šé€™è£¡ä¸å†åˆªé™¤ file_pathï¼Œå› ç‚º AudioTask éœ€è¦ä¿ç•™æª”æ¡ˆ


# ==========================================
# 2. æ–‡æœ¬æ‘˜è¦ä»»å‹™ (æ”¯æ´å­˜æª”)
# ==========================================

@shared_task(bind=True)
def summarize_text_task(self, text, summary_percentage='auto', audio_task_id=None):
    """
    æ¥æ”¶æ–‡æœ¬ -> è¼‰å…¥ Qwen æ¨¡å‹ -> ç”Ÿæˆæ‘˜è¦ -> (é¸ç”¨) å­˜å› DB
    """
    task_id = self.request.id
    logger.info(f"ğŸš€ [Task {task_id}] é–‹å§‹åŸ·è¡Œæ‘˜è¦ä»»å‹™ã€‚DB ID: {audio_task_id}")

    try:
        if not text:
            return {"status": "error", "error": "æ²’æœ‰æä¾›æ–‡æœ¬"}

        qwen_load_model()
        cleaned_text = _preprocess_text(text)
        min_len, max_len = calculate_dynamic_lengths(cleaned_text, summary_percentage)

        logger.info(f"[Task {task_id}] æ–‡æœ¬é•·åº¦: {len(cleaned_text)}, æ‘˜è¦ç¯„åœ: {min_len}-{max_len}")

        messages = [
            {"role": "system", "content": "ä½ æ˜¯æ‘˜è¦å°åŠ©æ‰‹ï¼Œè«‹æ ¹æ“šæ–‡æœ¬ï¼Œç”Ÿæˆé‡é»æ‘˜è¦ã€‚"},
            {"role": "user", "content": f"""é€™æ˜¯ä¸€æ®µèªéŸ³è½‰æ–‡å­—çš„çµæœï¼Œå¯èƒ½æœ‰éŒ¯èª¤ï¼Œä½ å¯ä»¥åœ¨æœ€å°å½±éŸ¿ä¸‹çŒœæ¸¬åŸæ„ï¼Œè«‹åŸºæ–¼ä»¥ä¸‹åŸå§‹æ–‡æœ¬ï¼Œç”Ÿæˆé‡é»æ‘˜è¦ã€‚
            è«‹å°‡æ‘˜è¦çš„é•·åº¦æ§åˆ¶åœ¨ **{min_len} åˆ° {max_len}** å€‹ token (è©å…ƒ) ä¹‹é–“ã€‚

            **åŸå§‹æ–‡æœ¬ï¼š**
            {cleaned_text}
            """}
        ]

        summary_result = generate_summary_with_qwen2_5(
            messages=messages,
            max_new_tokens=max_len * 3
        )

        final_summary = summary_result.get("summary", "")

        # [æ–°å¢] å¦‚æœæœ‰ audio_task_idï¼Œå°‡çµæœå¯«å›è³‡æ–™åº«
        if audio_task_id and final_summary:
            from .models import AudioTask  # å‡½å¼å…§åŒ¯å…¥é¿å…å¾ªç’°å¼•ç”¨
            try:
                task_obj = AudioTask.objects.get(id=audio_task_id)
                task_obj.summary = final_summary
                # åªæ›´æ–° summary èˆ‡ updated_at
                task_obj.save(update_fields=['summary', 'updated_at'])
                logger.info(f"ğŸ’¾ [Task {task_id}] æ‘˜è¦å·²å¯«å›è³‡æ–™åº« AudioTask: {audio_task_id}")
            except AudioTask.DoesNotExist:
                logger.warning(f"âš ï¸ [Task {task_id}] æ‰¾ä¸åˆ° AudioTask {audio_task_id}ï¼Œç•¥éå­˜æª”")

        logger.info(f"âœ… [Task {task_id}] æ‘˜è¦å®Œæˆï¼")
        return {
            "status": "success",
            "summary": final_summary,
            "original_length": len(text)
        }

    except Exception as e:
        logger.error(f"âŒ [Task {task_id}] æ‘˜è¦å¤±æ•—: {e}", exc_info=True)
        return {"status": "error", "error": str(e)}
    finally:
        if torch.cuda.is_available():
            torch.cuda.empty_cache()


# ==========================================
# 3. ç¿»è­¯ä»»å‹™ (æ”¯æ´å­˜æª”)
# ==========================================

def _detect_language_fallback(text):
    try:
        text_clean = re.sub(r'\s+', '', text)
        if not text_clean: return 'auto'
        if re.search(r'[\u4e00-\u9fff]', text_clean): return 'zh'
        if re.search(r'[\u3040-\u309f\u30a0-\u30ff]', text_clean): return 'ja'
        if re.search(r'[\uac00-\ud7af]', text_clean): return 'ko'
        return detect(text)
    except Exception:
        return 'auto'


async def _perform_translation_logic(text, target_language):
    translator = Translator()
    detected_lang = 'auto'

    try:
        detection = await translator.detect(text)
        detected_lang = detection.lang
        if (detected_lang == 'en' and re.search(r'[\u4e00-\u9fff]', text)) or \
                (detected_lang == 'ko' and re.search(r'[\u4e00-\u9fff]', text)):
            detected_lang = _detect_language_fallback(text)
    except Exception as e:
        logger.warning(f"Googletrans åµæ¸¬å¤±æ•—: {e}ï¼Œä½¿ç”¨å¾Œå‚™æ–¹æ¡ˆ")
        detected_lang = _detect_language_fallback(text)

    try:
        translated = await translator.translate(text, dest=target_language, src=detected_lang)
        return {
            "status": "success",
            "original_text": text,
            "source_language": detected_lang,
            "target_language": target_language,
            "translated_text": translated.text
        }
    except Exception as e:
        raise e


@shared_task(bind=True)
def translate_text_task(self, text, target_language, audio_task_id=None):
    """
    Celery ç¿»è­¯ä»»å‹™ -> (é¸ç”¨) å­˜å› DB
    """
    task_id = self.request.id
    logger.info(f"ğŸš€ [Task {task_id}] é–‹å§‹åŸ·è¡Œç¿»è­¯ä»»å‹™ã€‚ç›®æ¨™: {target_language}, DB ID: {audio_task_id}")

    try:
        if not text:
            return {"status": "error", "error": "æ²’æœ‰æä¾›æ–‡æœ¬"}

        result = asyncio.run(_perform_translation_logic(text, target_language))

        translated_text = result.get("translated_text", "")

        # [æ–°å¢] å¦‚æœæœ‰ audio_task_idï¼Œå°‡çµæœå¯«å›è³‡æ–™åº«
        if audio_task_id and translated_text:
            from .models import AudioTask  # å‡½å¼å…§åŒ¯å…¥
            try:
                task_obj = AudioTask.objects.get(id=audio_task_id)
                task_obj.translation = translated_text
                # åªæ›´æ–° translation èˆ‡ updated_at
                task_obj.save(update_fields=['translation', 'updated_at'])
                logger.info(f"ğŸ’¾ [Task {task_id}] ç¿»è­¯å·²å¯«å›è³‡æ–™åº« AudioTask: {audio_task_id}")
            except AudioTask.DoesNotExist:
                logger.warning(f"âš ï¸ [Task {task_id}] æ‰¾ä¸åˆ° AudioTask {audio_task_id}ï¼Œç•¥éå­˜æª”")

        logger.info(f"âœ… [Task {task_id}] ç¿»è­¯å®Œæˆï¼")
        return result

    except Exception as e:
        logger.error(f"âŒ [Task {task_id}] ç¿»è­¯å¤±æ•—: {e}", exc_info=True)
        error_msg = str(e)
        if "blocked" in error_msg.lower() or "quota" in error_msg.lower():
            error_msg = "ç¿»è­¯æœå‹™æš«æ™‚å—é™ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
        return {"status": "error", "error": error_msg}


@shared_task
def cleanup_expired_tasks():
    """
    æ¯å¤©åŸ·è¡Œä¸€æ¬¡ï¼šè‡ªå‹•åˆªé™¤éæœŸè³‡æ–™
    (å› ç‚ºè£äº† django-cleanupï¼Œåªè¦åˆªé™¤ DB ç´€éŒ„ï¼Œæª”æ¡ˆå°±æœƒè‡ªå‹•è¢«åˆªé™¤)
    """
    logger.info("ğŸ§¹ [Cleanup] é–‹å§‹åŸ·è¡ŒéæœŸè³‡æ–™æ¸…ç†...")
    from .models import AudioTask

    now = timezone.now()
    total_deleted = 0

    # 1. æ¸…ç†è¨ªå®¢è³‡æ–™ (Guest)
    guest_days = getattr(settings, 'GUEST_DATA_RETENTION_DAYS', 7)
    guest_threshold = now - timedelta(days=guest_days)

    # ç›´æ¥åˆªé™¤ QuerySetï¼Œdjango-cleanup æœƒç›£è½ä¸¦è™•ç†æª”æ¡ˆåˆªé™¤
    guest_deleted_count, _ = AudioTask.objects.filter(
        user__isnull=True,
        created_at__lt=guest_threshold
    ).delete()

    total_deleted += guest_deleted_count
    logger.info(f"   - å·²åˆªé™¤ {guest_deleted_count} ç­†è¨ªå®¢è³‡æ–™")

    # 2. æ¸…ç†æœƒå“¡è³‡æ–™ (Member) - é¸ç”¨
    member_days = getattr(settings, 'MEMBER_DATA_RETENTION_DAYS', None)
    if member_days:
        member_threshold = now - timedelta(days=member_days)
        member_deleted_count, _ = AudioTask.objects.filter(
            user__isnull=False,
            created_at__lt=member_threshold
        ).delete()

        total_deleted += member_deleted_count
        logger.info(f"   - å·²åˆªé™¤ {member_deleted_count} ç­†æœƒå“¡è³‡æ–™")

    return f"Cleanup complete. Deleted {total_deleted} tasks."
